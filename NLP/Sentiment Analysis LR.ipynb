{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from nltk.stem.rslp import RSLPStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import random\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "ls = LancasterStemmer()\n",
    "ts = ISRIStemmer()\n",
    "rss = RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\shoun\\\\Coding\\\\Datasets\\\\Movie Ratings')\n",
    "df5 = pd.read_csv('new processed.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>grew b watch lov thunderbird mat school watch ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>put movy dvd play sat cok chip expect hop movy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review  label\n",
       "0           0  grew b watch lov thunderbird mat school watch ...      0\n",
       "1           1  put movy dvd play sat cok chip expect hop movy...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5 = df5['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df5['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lst = []\n",
    "for i in x5:\n",
    "    a1 = re.sub('[^a-zA-Z]',' ',i)\n",
    "    a2 = a1.lower()\n",
    "    a = word_tokenize(a2)\n",
    "    b = [i for i in a if i not in stopwords.words('english')+list(punctuation)]\n",
    "    lst.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lst2 = []\n",
    "for i in lst:\n",
    "    a11 = []\n",
    "    for j in i:\n",
    "        a11.append(ls.stem(j))\n",
    "    lst2.append(a11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to check unique words in our comprehension\n",
    "# seta = []\n",
    "# for i in lst:\n",
    "#     for j in i:\n",
    "#         seta.append(j)\n",
    "# setb = set(seta)      \n",
    "# len(setb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corpus1 = []\n",
    "for i in range(0,40000):\n",
    "    corpus1.append(' '.join(lst2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus1[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(corpus1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processed_df = pd.DataFrame()\n",
    "processed_df['review'] = corpus1\n",
    "processed_df['label'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processed_df.to_csv('new processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 30000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(max_features=30000)\n",
    "X = cv.fit_transform(x5)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain, xtest, ytrain, ytest = train_test_split(X,y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cv.fit_transform(x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "ber = BernoulliNB()\n",
    "lr = LogisticRegression()\n",
    "cat = CategoricalNB()\n",
    "svc = SVC(kernel='sigmoid')\n",
    "lst_alg =[ber, svc,knn, lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BernoulliNB()               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88     20019\n",
      "           1       0.90      0.84      0.87     19981\n",
      "\n",
      "    accuracy                           0.87     40000\n",
      "   macro avg       0.87      0.87      0.87     40000\n",
      "weighted avg       0.87      0.87      0.87     40000\n",
      "\n",
      "\n",
      " SVC(kernel='sigmoid')               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60     20019\n",
      "           1       0.60      0.60      0.60     19981\n",
      "\n",
      "    accuracy                           0.60     40000\n",
      "   macro avg       0.60      0.60      0.60     40000\n",
      "weighted avg       0.60      0.60      0.60     40000\n",
      "\n",
      "\n",
      " KNeighborsClassifier()               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78     20019\n",
      "           1       0.80      0.70      0.75     19981\n",
      "\n",
      "    accuracy                           0.76     40000\n",
      "   macro avg       0.77      0.76      0.76     40000\n",
      "weighted avg       0.77      0.76      0.76     40000\n",
      "\n",
      "\n",
      " LogisticRegression()               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96     20019\n",
      "           1       0.96      0.97      0.96     19981\n",
      "\n",
      "    accuracy                           0.96     40000\n",
      "   macro avg       0.96      0.96      0.96     40000\n",
      "weighted avg       0.96      0.96      0.96     40000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shoun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for i in lst_alg:\n",
    "    i.fit(X, y)\n",
    "    ypred = i.predict(X_test)\n",
    "    print('\\n','{}'.format(i),classification_report(y, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hated the movie, it was waste of time. Direction was horrible. Script was poor. Acting was bad.\n",
      "Review is Negative\n"
     ]
    }
   ],
   "source": [
    "Review = str(input())\n",
    "input_data = [Review]\n",
    "\n",
    "input_data = cv.transform(input_data).toarray()\n",
    "\n",
    "input_pred = lr.predict(input_data)\n",
    "\n",
    "if input_pred[0]==1:\n",
    "    print(\"Review is Positive\")\n",
    "else:\n",
    "    print(\"Review is Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
